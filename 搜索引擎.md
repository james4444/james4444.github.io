# 数据结构与算法

## 搜索引擎

搜索引擎分为四个部分

* 搜集

利用爬虫爬取网页。把互联网看成一个有向图，把每个页面看成一个顶点，引用的链接看作指向另一个顶点的边，我们利用图的遍历，来遍历整个互联网中的网页。

搜索引擎采用的是广度优先的策略，我们先找一些权重比较高的链接，作为种子网页链接，放入到队列中，按照广度优先的策略，不停的从队列中取出链接，爬取对应的网页。

关键技术细节
1. 待爬取网页链接文件links.bin。链接放不下，可以存储到文件中。支持断点续爬

2. 网页判重，可以使用布隆过滤器 。为了防止断电导致布隆锅过滤器数据消失，我们可以将布隆过滤器存储到磁盘上，bloom_filter.bin，

3. 原始网页存储，合并存储，doc_raw.bin

4. 网页链接及其编号对应的文件 doc_id.bin。在存储网页的同时，我们将网页和编号的对应关系，存储在这个文件中。

* 分析

内容抽取、分词、构建倒排索引。网页爬取下来之后，我们需要对网页进行离线分析，分析主要包含两个步骤：
1. 抽取网页文本信息，去掉html标签
2. 分词并创建临时索引，基于字典或基于规则的分词。基于字典库的分词，我们可以利用trie树，取最长匹配。

* 索引

通过分析阶段的临时索引，构建倒排索引

* 查询

根据倒排索引，获得相关网页，计算网页排名，返回查询结果给用户